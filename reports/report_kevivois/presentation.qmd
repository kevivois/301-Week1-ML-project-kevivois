---
title: "Prédiction des Prix Immobiliers : Une Approche Comparative"
subtitle: "Analyse et Sélection de Modèles de Régression"
format:
  pdf:
    toc: true
    number-sections: true
---

# Présentation du Problème

Notre objectif est de prédire le prix de vente de maisons (problème de **régression supervisée**) à partir de leurs caractéristiques, en utilisant un modèle capable d'inférer une valeur continue.

![](images/inference_map.png){width=90%}

---

# Données et Modèles Testés
Les données utilisées proviennent d'un jeu de données immobilier, comprenant des caractéristiques telles que la surface, le nombre de pièces, l'année de construction, l'emplacement, etc. Chaque ligne correspond à une maison, avec son prix de vente comme variable cible.

Nous avons évalué plusieurs modèles de régression, en augmentant progressivement leur complexité :

- **Baseline :** Régression Linéaire simple (`LinearRegression`), qui sert de point de comparaison.
- **Régression Polynomiale :** Ajout de termes polynomiaux (`PolynomialFeatures`) pour des degrés de 2 à 6, afin de capturer des relations non linéaires.
- **Modèles Régularisés :** Combinaison de la régression polynomiale avec des techniques de régularisation :
- **Ridge (L2)** et **Lasso (L1)**, pour des degrés de 2 à 6 et des valeurs de `alpha` de 0 à 1000.

---

# Analyse des Résultats

Les graphiques ci-dessous présentent les performances des modèles selon deux métriques :
- **R² (score de détermination)** : mesure la qualité de la prédiction (plus proche de 1 = meilleur).
- **MAE (erreur absolue moyenne)** : mesure l'écart moyen entre les prix réels et prédits (plus bas = meilleur).

**Top 5 configurations R² :**
- Les meilleurs scores R² sont obtenus avec le modèle **Polynomial Lasso (degré=2, alpha=1000 à 200)**, atteignant jusqu'à **0.859**.
- À titre de comparaison, le modèle ayant la plus faible MAE (**Polynomial Ridge (degré=2, alpha=200)**) affiche un R² de **0.854**, soit très proche du meilleur modèle R².

**Top 5 configurations MAE :**
- Le modèle **Polynomial Ridge (degré=2, alpha=200)** obtient la plus faible MAE (**$18,410**), ce qui signifie qu'il minimise le coût moyen des erreurs de prédiction.
- À titre de comparaison, le meilleur modèle R² (**Polynomial Lasso (degré=2, alpha=1000)**) a une MAE de **$18,717**, soit une différence faible par rapport au meilleur MAE.

**Choix du modèle final :**
Les deux modèles sont très proches en termes de R² et de MAE.
J'ai choisi le modèle avec la plus faible MAE (**Polynomial Ridge (degré=2, alpha=200)**), car la valeur R² des deux modèles était quasiment identique, et minimiser l'erreur absolue moyenne est plus pertinent pour limiter l'impact financier des erreurs de prédiction.

---

## Graphs de comparaison des modèles
![](images/model_comparison_r2.png){width=100%}

Ce graphique compare les scores R² des différents modèles testés, illustrant leur capacité à expliquer la variance des prix immobiliers.

---

## Graphs de comparaison des modèles
![](images/model_comparison_MAE.png){width=100%}

Ce graphique présente la comparaison des erreurs absolues moyennes (MAE) pour chaque modèle, permettant d'évaluer la précision des prédictions.

---

# Choix de l'Ordre du Polynôme et Learning Curve

L'analyse comparative montre que le **degré polynomial 2** offre le meilleur compromis performance/complexité, les degrés supérieurs n'apportant pas d'amélioration significative.

*La **Learning Curve** ci-dessous confirme que notre modèle de degré 2 généralise bien : les scores d'entraînement et de validation convergent vers une performance élevée, indiquant une faible variance (pas de surapprentissage).*

![](images/learning_curve.png){width=90%}

---

# Présentation de la Régularisation Ajoutée

Pour éviter le surapprentissage, nous avons comparé deux techniques de régularisation : Ridge et Lasso.

- **Lasso (L1) :** Pénalise la somme des valeurs absolues des coefficients . Peut réduire des coefficients à zéro, réalisant ainsi une **sélection de variables**.
- **Ridge (L2) :** Pénalise la somme des carrés des coefficients. Réduit la magnitude des coefficients pour gérer la multicolinéarité.

Nous avons choisi **Ridge**, car il a produit une **erreur absolue moyenne (MAE) plus faible**, ce qui est plus pertinent pour évaluer l'impact monétaire des erreurs de prédiction.

---

# Meilleur Modèle : Choix et Résultats Finaux

Le meilleur modèle sélectionné est **`PolynomialFeatures(degree=2) + Ridge(alpha=200)`**.

- **Fonction Coût (Ridge) :** Ce modèle minimise la somme des carrés des résidus (RSS) plus une pénalité L2

- **Comparaison Finale (Validation Set) :**

| Modèle | R² | MAE |
| :--- | :--- | :--- |
| **Polynomial Ridge (deg=2, α=200)** | **0.854** | **$18410** |
| Polynomial Lasso (deg=2, α=1000) | 0.859 | $18717 |
| Régression Linéaire Simple | 0.84 | $19645 |

---

## Résultats sur le Jeu de Test

Le modèle final montre d'excellentes performances de généralisation.

::: {layout-ncol=2}
![](images/final_model_true_vs_predicted.png){width=95%}
![](images/final_model_residuals.png){width=95%}
:::

* mae: 18410  
* r2_score: 0.854
